# This is a Logstash configuration file for processing log files.

# Input section: This is where you specify the input source for Logstash to process.
input {
  file {
    path => "/usr/share/logstash/logs/app.log"          # The path to the log file.
    start_position => "beginning"                       # Start processing the log file from the beginning.
    sincedb_path => "/usr/share/logstash/data/sincedb"  # Path to sincedb file for keeping track of processed lines.
    #ssl => true                                        # Uncomment this line to enable SSL (if needed).
    #cacert => "/etc/ssl/certs/java/cacerts"            # Uncomment this line to specify the path to the CA certificate (if needed).

  }
  tcp {
    port => 4000
    ssl_enable => true
    ssl_cert => "/usr/share/logstash/config/certs/ca/ca.crt"
    ssl_key => "/usr/share/logstash/config/certs/ca/ca.key"
    # ssl_extra_chain_certs => ["/path/to/another-ca-file.ca"] # Uncomment this line if you need to provide an additional CA file for the certificate chain.
  }
}
    
# Filter section: This is where you process and enrich the input data.
filter {
  # Use the grok filter plugin to parse the log message using the COMBINEDAPACHELOG pattern.
  grok {
    match => { "message" => "%{COMBINEDAPACHELOG}" }
  }
  # Use the date filter plugin to parse the timestamp field and set it as the event's @timestamp field.
  date {
    match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    remove_field => "timestamp"       # Remove the original timestamp field.
  }
  # Use the mutate filter plugin to add a client_ip field with a predefined value.
  mutate {
    add_field => { "client_ip" => "172.16.6.129" }
  }
  
  # Use the geoip filter plugin to add geolocation information to the event based on the client_ip field.
  geoip {
    source => "[client_ip]"
    target => "[client.geo]"
  }
}
# Output section: This is where you specify the destination for the processed data.
output {
  elasticsearch {
    hosts => "https://es01:9200/"    # Elasticsearch host URL.
    index => "logs-%{+YYYY.MM.dd}"        # Index pattern for storing the data in Elasticsearch.
    user => "${ELASTIC_USERNAME}" # or the appropriate user if it's different 
    password => "${ELASTIC_PASSWORD}"  # replace with your actual password 
    ssl => true 
    cacert => "/usr/share/logstash/config/certs/es01/es01.crt" # replace with the path to your CA certificate file }
  }
  
  # Output the processed data to the console using the rubydebug codec.
  stdout {
    codec => rubydebug
  }
}
